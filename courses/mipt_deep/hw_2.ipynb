{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2. Языковые модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задача определения частей речи, Part-Of-Speech Tagger (POS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы будем решать задачу определения частей речи (POS-теггинга) с помощью скрытой марковской модели (HMM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import OrderedDict, deque\n",
    "from nltk.corpus import brown\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\Sergei\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"brown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем универсальную систему тегирования universal_tagset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\Sergei\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы имеем массив предложений пар (слово-тег)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('The', 'DET'), ('Fulton', 'NOUN'), ('County', 'NOUN'), ('Grand', 'ADJ'), ('Jury', 'NOUN'), ('said', 'VERB'), ('Friday', 'NOUN'), ('an', 'DET'), ('investigation', 'NOUN'), ('of', 'ADP'), (\"Atlanta's\", 'NOUN'), ('recent', 'ADJ'), ('primary', 'NOUN'), ('election', 'NOUN'), ('produced', 'VERB'), ('``', '.'), ('no', 'DET'), ('evidence', 'NOUN'), (\"''\", '.'), ('that', 'ADP'), ('any', 'DET'), ('irregularities', 'NOUN'), ('took', 'VERB'), ('place', 'NOUN'), ('.', '.')], [('The', 'DET'), ('jury', 'NOUN'), ('further', 'ADV'), ('said', 'VERB'), ('in', 'ADP'), ('term-end', 'NOUN'), ('presentments', 'NOUN'), ('that', 'ADP'), ('the', 'DET'), ('City', 'NOUN'), ('Executive', 'ADJ'), ('Committee', 'NOUN'), (',', '.'), ('which', 'DET'), ('had', 'VERB'), ('over-all', 'ADJ'), ('charge', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('election', 'NOUN'), (',', '.'), ('``', '.'), ('deserves', 'VERB'), ('the', 'DET'), ('praise', 'NOUN'), ('and', 'CONJ'), ('thanks', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('City', 'NOUN'), ('of', 'ADP'), ('Atlanta', 'NOUN'), (\"''\", '.'), ('for', 'ADP'), ('the', 'DET'), ('manner', 'NOUN'), ('in', 'ADP'), ('which', 'DET'), ('the', 'DET'), ('election', 'NOUN'), ('was', 'VERB'), ('conducted', 'VERB'), ('.', '.')], ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown_tagged_sents = brown.tagged_sents(tagset=\"universal\")\n",
    "brown_tagged_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.corpus.reader.util.ConcatenatedCorpusView"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(brown_tagged_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DET'),\n",
       " ('Fulton', 'NOUN'),\n",
       " ('County', 'NOUN'),\n",
       " ('Grand', 'ADJ'),\n",
       " ('Jury', 'NOUN'),\n",
       " ('said', 'VERB'),\n",
       " ('Friday', 'NOUN'),\n",
       " ('an', 'DET'),\n",
       " ('investigation', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " (\"Atlanta's\", 'NOUN'),\n",
       " ('recent', 'ADJ'),\n",
       " ('primary', 'NOUN'),\n",
       " ('election', 'NOUN'),\n",
       " ('produced', 'VERB'),\n",
       " ('``', '.'),\n",
       " ('no', 'DET'),\n",
       " ('evidence', 'NOUN'),\n",
       " (\"''\", '.'),\n",
       " ('that', 'ADP'),\n",
       " ('any', 'DET'),\n",
       " ('irregularities', 'NOUN'),\n",
       " ('took', 'VERB'),\n",
       " ('place', 'NOUN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown_tagged_sents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DET'),\n",
       " ('Fulton', 'NOUN'),\n",
       " ('County', 'NOUN'),\n",
       " ('Grand', 'ADJ'),\n",
       " ('Jury', 'NOUN'),\n",
       " ('said', 'VERB'),\n",
       " ('Friday', 'NOUN'),\n",
       " ('an', 'DET'),\n",
       " ('investigation', 'NOUN'),\n",
       " ('of', 'ADP')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown_tagged_words = brown.tagged_words(tagset='universal')\n",
    "brown_tagged_words[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проанализируем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_tagged_words = list(map(lambda x: (x[0].lower(), x[1]), brown_tagged_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 'DET'),\n",
       " ('fulton', 'NOUN'),\n",
       " ('county', 'NOUN'),\n",
       " ('grand', 'ADJ'),\n",
       " ('jury', 'NOUN'),\n",
       " ('said', 'VERB'),\n",
       " ('friday', 'NOUN'),\n",
       " ('an', 'DET'),\n",
       " ('investigation', 'NOUN'),\n",
       " ('of', 'ADP')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown_tagged_words[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1161192"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(brown_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(nltk.FreqDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во предложений:  57340\n"
     ]
    }
   ],
   "source": [
    "print('Кол-во предложений: ', len(brown_tagged_sents))\n",
    "tags = [tag for (word, tag) in brown_tagged_words]\n",
    "words = [word for (word, tag) in brown_tagged_words]\n",
    "\n",
    "tag_num = pd.Series(nltk.FreqDist(tags)).sort_values(ascending=False)\n",
    "word_num = pd.Series(nltk.FreqDist(words)).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.bar(tag_num.index, tag_num.values)\n",
    "plt.title(\"Tag_frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.bar(word_num.index[:10], word_num.values[:10])\n",
    "plt.title(\"Word_frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вопрос 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кол-во слова cat в корпусе?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_num['cat']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вопрос 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самое популярное слово с самым популярным тегом?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time\n"
     ]
    }
   ],
   "source": [
    "most_popular_tag = tag_num.index[0]\n",
    "\n",
    "#NOUN\n",
    "words_with_popular_tag = [word for (word,tag) in brown_tagged_words if tag == most_popular_tag]\n",
    "\n",
    "pop_word = pd.Series(nltk.FreqDist(words_with_popular_tag)).sort_values(ascending=False).index[0]\n",
    "\n",
    "print(pop_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Категории корпуса:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.categories()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем работать с категорией humor\n",
    "\n",
    "Cделайте случайное разбиение выборки на обучение и контроль в отношении 9:1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'brown' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-fa887f51ce36>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbrown_tagged_sents\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbrown\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtagged_sents\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtagset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"universal\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmy_brown_tagged_sents\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbrown_tagged_sents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mmy_brown_tagged_sents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'brown' is not defined"
     ]
    }
   ],
   "source": [
    "brown_tagged_sents = brown.tagged_sents(tagset=\"universal\")\n",
    "my_brown_tagged_sents = []\n",
    "\n",
    "for sent in brown_tagged_sents:\n",
    "    my_brown_tagged_sents.append(list(map(lambda x: (x[0].lower(),x[1]), sent)))\n",
    "\n",
    "my_brown_tagged_sents = np.array(my_brown_tagged_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sents, test_sents = train_test_split(my_brown_tagged_sents, test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "947"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Марковские цепи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Обучение] Метод максимального правдоподобия для обучения модели\n",
    "\n",
    "* $\\normalsize S = s_0, s_1, ..., s_N$ - скрытые состояния, то есть различные теги\n",
    "* $\\normalsize O = o_0, o_1, ..., o_M$ - различные слова\n",
    "* $\\normalsize a_{i,j} = p(s_j|s_i)$ - вероятность того, что, находясь в скрытом состоянии $s_i$, мы попадем в состояние $s_j$ (элемент матрицы $A$)\n",
    "* $\\normalsize b_{k,j}=p(o_k|s_j)$ - вероятность того, что при скрытом состоянии $s_j$ находится слово $o_k$(элемент матрицы $B$)\n",
    "\n",
    "$$\\normalsize x_t \\in O, y_t \\in S$$\n",
    "$\\normalsize (x_t, y_t)$ - слово и тег, стоящие на месте $t$ $\\Rightarrow$ \n",
    "* $\\normalsize X$ - последовательность слов\n",
    "* $\\normalsize Y$ - последовательность тегов\n",
    "\n",
    "Требуется построить скрытую марковскую модель (class HiddenMarkovModel) и написать метод fit для настройки всех её параметров с помощью оценок максимального правдоподобия по размеченным данным (последовательности пар слово+тег):\n",
    "\n",
    "- Вероятности переходов между скрытыми состояниями $p(y_t | y_{t - 1})$ посчитайте на основе частот биграмм POS-тегов.\n",
    "\n",
    "\n",
    "- Вероятности эмиссий наблюдаемых состояний $p(x_t | y_t)$ посчитайте на основе частот \"POS-тег - слово\".\n",
    "\n",
    "\n",
    "- Распределение вероятностей начальных состояний $p(y_0)$ задайте равномерным.\n",
    "\n",
    "Пример $X = [x_0, x_1], Y = [y_0, y_1]$:<br><br>\n",
    "$$p(X, Y) = p(x_0, x_1, y_0, y_1) = p(y_0) \\cdot p(x_0, x_1, y_1 | y_0) = p(y_0) \\cdot p(x_0 | y_0) \\cdot\n",
    "p(x_1, y_1 | x_0, y_0) = \\\\ = p(y_0) \\cdot p(x_0 | y_0) \\cdot p(y_1 | x_0, y_0) \\cdot p(x_1 | x_0, y_0, y_1)\n",
    "= (\\text{в силу условий наши модели}) = p(y_0) \\cdot p(x_0 | y_0) \\cdot p(y_1 | y_0) \\cdot p(x_1 | y_1) \\Rightarrow$$ <br>\n",
    "Для последовательности длины $n + 1$:<br>\n",
    "$$p(X, Y) = p(x_0 ... x_{n - 1}, y_0 ... y_{n - 1}) \\cdot p(y_n | y_{n - 1}) \\cdot p(x_n | y_n)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Предсказание] Алгоритм Витерби для применения модели\n",
    "\n",
    "\n",
    "Требуется написать метод .predict для определения частей речи на тестовой выборке. Чтобы использовать обученную модель на новых данных, необходимо реализовать алгоритм Витерби. Это алгоритм динамического программирования, с помощью которого мы будем находить наиболее вероятную последовательность скрытых состояний модели для фиксированной последовательности слов:\n",
    "\n",
    "$$ \\hat{Y} = \\arg \\max_{Y} p(Y|X) = \\arg \\max_{Y} p(Y, X) $$\n",
    "\n",
    "Пусть $\\normalsize Q_{t,s}$ - самая вероятная последовательность скрытых состояний длины $t$ с окончанием в состоянии $s$. $\\normalsize q_{t, s}$ - вероятность этой последовательности.\n",
    "$$(1)\\: \\normalsize q_{t,s} = \\max_{s'} q_{t - 1, s'} \\cdot p(s | s') \\cdot p(o_t | s)$$\n",
    "$\\normalsize Q_{t,s}$ можно восстановить по argmax-ам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiddenMarkovModel:    \n",
    "    def __init__(self):\n",
    "    \n",
    "        pass\n",
    "        \n",
    "    def fit(self, train_tokens_tags_list):\n",
    "        \"\"\"\n",
    "        train_tokens_tags_list: массив предложений пар слово-тег (выборка для train) \n",
    "        \"\"\"\n",
    "        tags = [tag for sent in train_tokens_tags_list\n",
    "                    for (word, tag) in sent]\n",
    "        words = [word for sent in train_tokens_tags_list\n",
    "                      for (word, tag) in sent]\n",
    "        \n",
    "        tag_num = pd.Series(nltk.FreqDist(tags)).sort_index()\n",
    "        word_num = pd.Series(nltk.FreqDist(words)).sort_values(ascending=False)\n",
    "         \n",
    "        self.tags = tag_num.index\n",
    "        self.words = word_num.index\n",
    "        \n",
    "        A = pd.DataFrame({'{}'.format(tag) : [0] * len(tag_num) for tag in tag_num.index}, index=tag_num.index)\n",
    "        B = pd.DataFrame({'{}'.format(tag) : [0] * len(word_num) for tag in tag_num.index}, index=word_num.index)\n",
    "        \n",
    "        # Вычисляем матрицу A и B по частотам слов и тегов\n",
    "        \n",
    "        # sent - предложение\n",
    "        # sent[i][0] - i слово в этом предложении, sent[i][1] - i тег в этом предложении\n",
    "        for sent in train_tokens_tags_list:\n",
    "            for i in range(len(sent)):\n",
    "                B.loc[sent[i][0], sent[i][1]] += 1 # текущая i-пара слово-тег (обновите матрицу B аналогично A)\n",
    "                if len(sent) - 1 != i: # для последнего тега нет следующего тега\n",
    "                    A.loc[sent[i][1], sent[i + 1][1]] += 1 # пара тег-тег\n",
    "                \n",
    "        \n",
    "        # переходим к вероятностям\n",
    "        \n",
    "        # нормируем по строке, то есть по всем всевозможным следующим тегам\n",
    "        A = A.divide(A.sum(axis=1), axis=0)\n",
    "        \n",
    "        # нормируем по столбцу, то есть по всем всевозможным текущим словам\n",
    "        B = B / np.sum(B, axis=0)\n",
    "        \n",
    "        self.A = A\n",
    "        self.B = B\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    \n",
    "    def predict(self, test_tokens_list):\n",
    "        \"\"\"\n",
    "        test_tokens_list : массив предложений пар слово-тег (выборка для test)\n",
    "        \"\"\"\n",
    "        predict_tags = OrderedDict({i : np.array([]) for i in range(len(test_tokens_list))})\n",
    "        \n",
    "        for i_sent in range(len(test_tokens_list)):\n",
    "            \n",
    "            current_sent = test_tokens_list[i_sent] # текущее предложение\n",
    "            len_sent = len(current_sent) # длина предложения \n",
    "            \n",
    "            q = np.zeros(shape=(len_sent + 1, len(self.tags)))\n",
    "            q[0] = 1 # нулевое состояние (равномерная инициализация по всем s)\n",
    "            back_point = np.zeros(shape=(len_sent + 1, len(self.tags))) # # argmax\n",
    "            \n",
    "            for t in range(len_sent):\n",
    "                \n",
    "                # если мы не встречали такое слово в обучении, то вместо него будет \n",
    "                # самое популярное слово с самым популярным тегом (вопрос 2)\n",
    "                if current_sent[t] not in self.words:\n",
    "                    current_sent[t] = pop_word\n",
    "                    \n",
    "                # через max выбираем следующий тег\n",
    "                for i_s in range(len(self.tags)):\n",
    "                    \n",
    "                    s = self.tags[i_s]\n",
    "                    \n",
    "                    # формула (1)\n",
    "                    q[t + 1][i_s] = np.max(q[t,:] *\n",
    "                        self.A.loc[:, s] * \n",
    "                        self.B.loc[current_sent[t], s])\n",
    "                    \n",
    "                    # argmax формула(1)\n",
    "                    \n",
    "                    # argmax, чтобы восстановить последовательность тегов\n",
    "                    back_point[t + 1][i_s] = (q[t,:] *\n",
    "                        self.A.loc[:, s] * \n",
    "                        self.B.loc[current_sent[t], s]).reset_index()[s].idxmax() # индекс \n",
    "                    \n",
    "            back_point = back_point.astype('int')\n",
    "            \n",
    "            # выписываем теги, меняя порядок на реальный\n",
    "            back_tag = deque()\n",
    "            current_tag = np.argmax(q[len_sent])\n",
    "            for t in range(len_sent, 0, -1):\n",
    "                back_tag.appendleft(self.tags[current_tag])\n",
    "                current_tag = back_point[t, current_tag]\n",
    "             \n",
    "            predict_tags[i_sent] = np.array(back_tag)\n",
    "        \n",
    "        \n",
    "        return predict_tags   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.HiddenMarkovModel at 0x23a19be7a88>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markov_model = HiddenMarkovModel()\n",
    "markov_model.fit(train_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADV</th>\n",
       "      <th>CONJ</th>\n",
       "      <th>DET</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>NUM</th>\n",
       "      <th>PRON</th>\n",
       "      <th>PRT</th>\n",
       "      <th>VERB</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0.238316</td>\n",
       "      <td>0.035632</td>\n",
       "      <td>0.094863</td>\n",
       "      <td>0.060157</td>\n",
       "      <td>0.096714</td>\n",
       "      <td>0.104118</td>\n",
       "      <td>0.100416</td>\n",
       "      <td>0.006941</td>\n",
       "      <td>0.106432</td>\n",
       "      <td>0.038871</td>\n",
       "      <td>0.114299</td>\n",
       "      <td>0.003239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ</th>\n",
       "      <td>0.154096</td>\n",
       "      <td>0.057583</td>\n",
       "      <td>0.090835</td>\n",
       "      <td>0.012976</td>\n",
       "      <td>0.034063</td>\n",
       "      <td>0.007299</td>\n",
       "      <td>0.585564</td>\n",
       "      <td>0.002433</td>\n",
       "      <td>0.010543</td>\n",
       "      <td>0.027575</td>\n",
       "      <td>0.013788</td>\n",
       "      <td>0.003244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADP</th>\n",
       "      <td>0.019752</td>\n",
       "      <td>0.055581</td>\n",
       "      <td>0.022508</td>\n",
       "      <td>0.017915</td>\n",
       "      <td>0.000919</td>\n",
       "      <td>0.462563</td>\n",
       "      <td>0.235645</td>\n",
       "      <td>0.017915</td>\n",
       "      <td>0.110243</td>\n",
       "      <td>0.020211</td>\n",
       "      <td>0.035829</td>\n",
       "      <td>0.000919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV</th>\n",
       "      <td>0.188269</td>\n",
       "      <td>0.157048</td>\n",
       "      <td>0.101230</td>\n",
       "      <td>0.086093</td>\n",
       "      <td>0.014191</td>\n",
       "      <td>0.063387</td>\n",
       "      <td>0.032167</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>0.073794</td>\n",
       "      <td>0.027436</td>\n",
       "      <td>0.248817</td>\n",
       "      <td>0.000946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CONJ</th>\n",
       "      <td>0.055385</td>\n",
       "      <td>0.096923</td>\n",
       "      <td>0.066154</td>\n",
       "      <td>0.095385</td>\n",
       "      <td>0.001538</td>\n",
       "      <td>0.149231</td>\n",
       "      <td>0.167692</td>\n",
       "      <td>0.016923</td>\n",
       "      <td>0.106154</td>\n",
       "      <td>0.021538</td>\n",
       "      <td>0.218462</td>\n",
       "      <td>0.004615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DET</th>\n",
       "      <td>0.018993</td>\n",
       "      <td>0.220406</td>\n",
       "      <td>0.006184</td>\n",
       "      <td>0.020760</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>0.646201</td>\n",
       "      <td>0.006625</td>\n",
       "      <td>0.017226</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>0.053004</td>\n",
       "      <td>0.002650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN</th>\n",
       "      <td>0.329605</td>\n",
       "      <td>0.011186</td>\n",
       "      <td>0.218742</td>\n",
       "      <td>0.035297</td>\n",
       "      <td>0.062391</td>\n",
       "      <td>0.017151</td>\n",
       "      <td>0.128511</td>\n",
       "      <td>0.001740</td>\n",
       "      <td>0.026597</td>\n",
       "      <td>0.018891</td>\n",
       "      <td>0.149142</td>\n",
       "      <td>0.000746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>0.095890</td>\n",
       "      <td>0.116438</td>\n",
       "      <td>0.136986</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041096</td>\n",
       "      <td>0.006849</td>\n",
       "      <td>0.534247</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006849</td>\n",
       "      <td>0.034247</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRON</th>\n",
       "      <td>0.103948</td>\n",
       "      <td>0.004029</td>\n",
       "      <td>0.061241</td>\n",
       "      <td>0.063658</td>\n",
       "      <td>0.007252</td>\n",
       "      <td>0.024174</td>\n",
       "      <td>0.003223</td>\n",
       "      <td>0.005641</td>\n",
       "      <td>0.007252</td>\n",
       "      <td>0.019339</td>\n",
       "      <td>0.699436</td>\n",
       "      <td>0.000806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRT</th>\n",
       "      <td>0.128501</td>\n",
       "      <td>0.014827</td>\n",
       "      <td>0.088962</td>\n",
       "      <td>0.059308</td>\n",
       "      <td>0.011532</td>\n",
       "      <td>0.088962</td>\n",
       "      <td>0.018122</td>\n",
       "      <td>0.003295</td>\n",
       "      <td>0.006590</td>\n",
       "      <td>0.013180</td>\n",
       "      <td>0.566722</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERB</th>\n",
       "      <td>0.110974</td>\n",
       "      <td>0.042848</td>\n",
       "      <td>0.158755</td>\n",
       "      <td>0.094328</td>\n",
       "      <td>0.016030</td>\n",
       "      <td>0.165228</td>\n",
       "      <td>0.081689</td>\n",
       "      <td>0.007090</td>\n",
       "      <td>0.081073</td>\n",
       "      <td>0.078915</td>\n",
       "      <td>0.162454</td>\n",
       "      <td>0.000617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>0.301887</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075472</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.113208</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.433962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             .       ADJ       ADP       ADV      CONJ       DET      NOUN  \\\n",
       ".     0.238316  0.035632  0.094863  0.060157  0.096714  0.104118  0.100416   \n",
       "ADJ   0.154096  0.057583  0.090835  0.012976  0.034063  0.007299  0.585564   \n",
       "ADP   0.019752  0.055581  0.022508  0.017915  0.000919  0.462563  0.235645   \n",
       "ADV   0.188269  0.157048  0.101230  0.086093  0.014191  0.063387  0.032167   \n",
       "CONJ  0.055385  0.096923  0.066154  0.095385  0.001538  0.149231  0.167692   \n",
       "DET   0.018993  0.220406  0.006184  0.020760  0.000442  0.005300  0.646201   \n",
       "NOUN  0.329605  0.011186  0.218742  0.035297  0.062391  0.017151  0.128511   \n",
       "NUM   0.095890  0.116438  0.136986  0.000000  0.041096  0.006849  0.534247   \n",
       "PRON  0.103948  0.004029  0.061241  0.063658  0.007252  0.024174  0.003223   \n",
       "PRT   0.128501  0.014827  0.088962  0.059308  0.011532  0.088962  0.018122   \n",
       "VERB  0.110974  0.042848  0.158755  0.094328  0.016030  0.165228  0.081689   \n",
       "X     0.301887  0.000000  0.075472  0.018868  0.018868  0.000000  0.113208   \n",
       "\n",
       "           NUM      PRON       PRT      VERB         X  \n",
       ".     0.006941  0.106432  0.038871  0.114299  0.003239  \n",
       "ADJ   0.002433  0.010543  0.027575  0.013788  0.003244  \n",
       "ADP   0.017915  0.110243  0.020211  0.035829  0.000919  \n",
       "ADV   0.006623  0.073794  0.027436  0.248817  0.000946  \n",
       "CONJ  0.016923  0.106154  0.021538  0.218462  0.004615  \n",
       "DET   0.006625  0.017226  0.002208  0.053004  0.002650  \n",
       "NOUN  0.001740  0.026597  0.018891  0.149142  0.000746  \n",
       "NUM   0.027397  0.000000  0.006849  0.034247  0.000000  \n",
       "PRON  0.005641  0.007252  0.019339  0.699436  0.000806  \n",
       "PRT   0.003295  0.006590  0.013180  0.566722  0.000000  \n",
       "VERB  0.007090  0.081073  0.078915  0.162454  0.000617  \n",
       "X     0.000000  0.018868  0.000000  0.018868  0.433962  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markov_model.A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADV</th>\n",
       "      <th>CONJ</th>\n",
       "      <th>DET</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>NUM</th>\n",
       "      <th>PRON</th>\n",
       "      <th>PRT</th>\n",
       "      <th>VERB</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>0.389694</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.414311</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0.254428</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.212898</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.738462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gaming</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dissipated</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monies</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clothes</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>let's</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4466 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   .  ADJ  ADP  ADV      CONJ       DET      NOUN  NUM  PRON  \\\n",
       ",           0.389694  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.0   0.0   \n",
       "the         0.000000  0.0  0.0  0.0  0.000000  0.414311  0.000000  0.0   0.0   \n",
       ".           0.254428  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.0   0.0   \n",
       "a           0.000000  0.0  0.0  0.0  0.000000  0.212898  0.000000  0.0   0.0   \n",
       "and         0.000000  0.0  0.0  0.0  0.738462  0.000000  0.000000  0.0   0.0   \n",
       "...              ...  ...  ...  ...       ...       ...       ...  ...   ...   \n",
       "gaming      0.000000  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.0   0.0   \n",
       "dissipated  0.000000  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.0   0.0   \n",
       "monies      0.000000  0.0  0.0  0.0  0.000000  0.000000  0.000248  0.0   0.0   \n",
       "clothes     0.000000  0.0  0.0  0.0  0.000000  0.000000  0.000248  0.0   0.0   \n",
       "let's       0.000000  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.0   0.0   \n",
       "\n",
       "            PRT      VERB    X  \n",
       ",           0.0  0.000000  0.0  \n",
       "the         0.0  0.000000  0.0  \n",
       ".           0.0  0.000000  0.0  \n",
       "a           0.0  0.000000  0.0  \n",
       "and         0.0  0.000000  0.0  \n",
       "...         ...       ...  ...  \n",
       "gaming      0.0  0.000308  0.0  \n",
       "dissipated  0.0  0.000308  0.0  \n",
       "monies      0.0  0.000000  0.0  \n",
       "clothes     0.0  0.000000  0.0  \n",
       "let's       0.0  0.000308  0.0  \n",
       "\n",
       "[4466 rows x 12 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markov_model.B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверьте работу реализованного алгоритма на следующих модельных примерах, проинтерпретируйте результат.\n",
    "\n",
    "'He can stay'\n",
    "'a cat and a dog'\n",
    "'I have a television'\n",
    "'My favourite character'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = [['He', 'can', 'stay'], ['a', 'cat', 'and', 'a', 'dog'], ['I', 'have', 'a', 'television'],\n",
    "         ['My', 'favourite', 'character']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([(0, array(['NOUN', 'VERB', 'VERB'], dtype='<U4')),\n",
       "             (1, array(['DET', 'NOUN', 'CONJ', 'DET', 'NOUN'], dtype='<U4')),\n",
       "             (2, array(['NOUN', 'VERB', 'DET', 'NOUN'], dtype='<U4')),\n",
       "             (3, array(['NOUN', 'NOUN', 'NOUN'], dtype='<U4'))])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markov_model.predict(sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В целом алгоритм работает. В последнем предложении не правильно определились прилагательные (слова favourite нет в словаре, поэтому подставилось самое популярное слово с самым популярным тегом (time))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вопрос 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какой тег вы получили для слова can?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VERB'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markov_model.predict([['can']])[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вопрос 4:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какой тег вы получили для слова favourite?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NOUN'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markov_model.predict([['favourite']])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ADJ'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markov_model.predict([['favorite']])[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примените модель к отложенной выборке Брауновского корпуса и подсчитайте точность определения тегов (accuracy). Сделайте выводы. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score(model, sents):\n",
    "    true_pred = 0\n",
    "    num_pred = 0\n",
    "\n",
    "    for sent in sents:        \n",
    "        tags = [tag for (word,tag) in sent]\n",
    "        words = [word for (word,tag) in sent]\n",
    "\n",
    "        outputs = markov_model.predict([words])[0]        \n",
    "        true_pred += np.sum(tags == outputs)\n",
    "        \n",
    "        num_pred += len(words)\n",
    "    acc = true_pred / num_pred * 100\n",
    "    print(\"Accuracy:\", true_pred / num_pred * 100, '%')\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.4291754756871 %\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(markov_model, test_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод: нужно обучиться на большем корпусе, чтобы увеличить словарь."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вопрос 5:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какое качество вы получили(округлите до одного знака после запятой)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.4291754756871\n"
     ]
    }
   ],
   "source": [
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. DefaultTagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вопрос 6:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какое качество вы бы получили, если бы предсказывали любой тег, как самый популярный тег на выборке train(округлите до одного знака после запятой)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 20.031712473572938 %\n"
     ]
    }
   ],
   "source": [
    "true_pred = 0\n",
    "num_pred = 0\n",
    "\n",
    "for sent in test_sents:\n",
    "    tags = np.array([tag for (word, tag) in sent])\n",
    "    words = np.array([word for (word, tag) in sent])\n",
    "\n",
    "    true_pred += np.sum(['NOUN'] * len(words) == tags)\n",
    "    num_pred += len(words)\n",
    "print(\"Accuracy:\", true_pred / num_pred * 100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вы можете испоьзовать DefaultTagger(метод tag для предсказания частей речи предложения) или можете преобразовать код выше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import DefaultTagger\n",
    "default_tagger = DefaultTagger('NOUN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 20.031712473572938 %\n"
     ]
    }
   ],
   "source": [
    "true_pred = 0\n",
    "num_pred = 0\n",
    "\n",
    "for sent in test_sents:\n",
    "    tags = np.array([tag for (word, tag) in sent])\n",
    "    words = np.array([word for (word, tag) in sent])\n",
    "    \n",
    "    tagged_sent = default_tagger.tag(words)\n",
    "    outputs = [tag for token, tag in tagged_sent]\n",
    "    \n",
    "    true_pred += np.sum(outputs == tags)\n",
    "    num_pred += len(words)\n",
    "    \n",
    "print(\"Accuracy:\", true_pred / num_pred * 100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Модель Стенфорда"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачайте предобученную модель от Стэнфорда: https://nlp.stanford.edu/software/tagger.shtml и примените к тестовым данным. Не забудьте преобразовать систему тэгов из 'en-ptb' в 'universal' с помощью функции map_tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ответ:  ['PRON', 'VERB', 'DET', 'NOUN']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tag.stanford import StanfordPOSTagger\n",
    "from nltk.tag.mapping import map_tag\n",
    "\n",
    "# используйте путь до jar и до model\n",
    "jar = u'D:\\ml\\stanford-postagger-2018-10-16\\stanford-postagger-3.9.2.jar'\n",
    "model = u'D:\\ml\\stanford-postagger-2018-10-16\\models\\english-bidirectional-distsim.tagger'\n",
    "stanford_tagger = StanfordPOSTagger(model, jar, encoding='utf8')\n",
    "\n",
    "# проверим на предложении\n",
    "tagged_sent = stanford_tagger.tag(['I', 'bear', 'a', 'bag'])\n",
    "print('Ответ: ', [map_tag('en-ptb', 'universal', tag) for token, tag in tagged_sent])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вопрос 7:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какое качество вы получили на модели Стенфорда?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.9090909090909 %\n"
     ]
    }
   ],
   "source": [
    "true_pred = 0\n",
    "num_pred = 0\n",
    "\n",
    "for sent in test_sents:\n",
    "    tags = np.array([tag for (word, tag) in sent])\n",
    "    words = np.array([word for (word, tag) in sent])\n",
    "    \n",
    "    tagged_sent = stanford_tagger.tag(words)\n",
    "    outputs = [map_tag('en-ptb', 'universal', tag) for token, tag in tagged_sent]\n",
    "    \n",
    "    true_pred += np.sum(outputs == tags)\n",
    "    num_pred += len(words)\n",
    "    \n",
    "print(\"Accuracy:\", true_pred / num_pred * 100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. BiLSTMTagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим данные. Возьмем полный датасет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_tagged_sents = brown.tagged_sents(tagset=\"universal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.'), ('DET', 'NOUN', 'NOUN', 'ADJ', 'NOUN', 'VERB', 'NOUN', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADJ', 'NOUN', 'NOUN', 'VERB', '.', 'DET', 'NOUN', '.', 'ADP', 'DET', 'NOUN', 'VERB', 'NOUN', '.')]\n"
     ]
    }
   ],
   "source": [
    "pos_data = [list(zip(*sent)) for sent in brown_tagged_sents]\n",
    "print(pos_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем модель на torch'e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Field, BucketIterator\n",
    "import torchtext\n",
    "\n",
    "# наши поля\n",
    "WORD = Field(lower=True)\n",
    "TAG = Field(unk_token=None) # все токены нам извсетны\n",
    "\n",
    "# создаем примеры\n",
    "examples = []\n",
    "for words, tags in pos_data:\n",
    "    examples.append(torchtext.data.Example.fromlist([list(words), list(tags)], fields=[('words', WORD), ('tags', TAG)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 45872\n",
      "Number of validation examples: 5734\n",
      "Number of testing examples: 5734\n"
     ]
    }
   ],
   "source": [
    "# кладем примеры в наш датасет\n",
    "dataset = torchtext.data.Dataset(examples, fields=[('words', WORD), ('tags', TAG)])\n",
    "\n",
    "train_data, valid_data, test_data = dataset.split(split_ratio=[0.8, 0.1, 0.1])\n",
    "\n",
    "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
    "print(f\"Number of validation examples: {len(valid_data.examples)}\")\n",
    "print(f\"Number of testing examples: {len(test_data.examples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Field in module torchtext.data.field:\n",
      "\n",
      "class Field(RawField)\n",
      " |  Field(sequential=True, use_vocab=True, init_token=None, eos_token=None, fix_length=None, dtype=torch.int64, preprocessing=None, postprocessing=None, lower=False, tokenize=None, tokenizer_language='en', include_lengths=False, batch_first=False, pad_token='<pad>', unk_token='<unk>', pad_first=False, truncate_first=False, stop_words=None, is_target=False)\n",
      " |  \n",
      " |  Defines a datatype together with instructions for converting to Tensor.\n",
      " |  \n",
      " |  Field class models common text processing datatypes that can be represented\n",
      " |  by tensors.  It holds a Vocab object that defines the set of possible values\n",
      " |  for elements of the field and their corresponding numerical representations.\n",
      " |  The Field object also holds other parameters relating to how a datatype\n",
      " |  should be numericalized, such as a tokenization method and the kind of\n",
      " |  Tensor that should be produced.\n",
      " |  \n",
      " |  If a Field is shared between two columns in a dataset (e.g., question and\n",
      " |  answer in a QA dataset), then they will have a shared vocabulary.\n",
      " |  \n",
      " |  Attributes:\n",
      " |      sequential: Whether the datatype represents sequential data. If False,\n",
      " |          no tokenization is applied. Default: True.\n",
      " |      use_vocab: Whether to use a Vocab object. If False, the data in this\n",
      " |          field should already be numerical. Default: True.\n",
      " |      init_token: A token that will be prepended to every example using this\n",
      " |          field, or None for no initial token. Default: None.\n",
      " |      eos_token: A token that will be appended to every example using this\n",
      " |          field, or None for no end-of-sentence token. Default: None.\n",
      " |      fix_length: A fixed length that all examples using this field will be\n",
      " |          padded to, or None for flexible sequence lengths. Default: None.\n",
      " |      dtype: The torch.dtype class that represents a batch of examples\n",
      " |          of this kind of data. Default: torch.long.\n",
      " |      preprocessing: The Pipeline that will be applied to examples\n",
      " |          using this field after tokenizing but before numericalizing. Many\n",
      " |          Datasets replace this attribute with a custom preprocessor.\n",
      " |          Default: None.\n",
      " |      postprocessing: A Pipeline that will be applied to examples using\n",
      " |          this field after numericalizing but before the numbers are turned\n",
      " |          into a Tensor. The pipeline function takes the batch as a list, and\n",
      " |          the field's Vocab.\n",
      " |          Default: None.\n",
      " |      lower: Whether to lowercase the text in this field. Default: False.\n",
      " |      tokenize: The function used to tokenize strings using this field into\n",
      " |          sequential examples. If \"spacy\", the SpaCy tokenizer is\n",
      " |          used. If a non-serializable function is passed as an argument,\n",
      " |          the field will not be able to be serialized. Default: string.split.\n",
      " |      tokenizer_language: The language of the tokenizer to be constructed.\n",
      " |          Various languages currently supported only in SpaCy.\n",
      " |      include_lengths: Whether to return a tuple of a padded minibatch and\n",
      " |          a list containing the lengths of each examples, or just a padded\n",
      " |          minibatch. Default: False.\n",
      " |      batch_first: Whether to produce tensors with the batch dimension first.\n",
      " |          Default: False.\n",
      " |      pad_token: The string token used as padding. Default: \"<pad>\".\n",
      " |      unk_token: The string token used to represent OOV words. Default: \"<unk>\".\n",
      " |      pad_first: Do the padding of the sequence at the beginning. Default: False.\n",
      " |      truncate_first: Do the truncating of the sequence at the beginning. Default: False\n",
      " |      stop_words: Tokens to discard during the preprocessing step. Default: None\n",
      " |      is_target: Whether this field is a target variable.\n",
      " |          Affects iteration over batches. Default: False\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Field\n",
      " |      RawField\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __hash__(self)\n",
      " |      Return hash(self).\n",
      " |  \n",
      " |  __init__(self, sequential=True, use_vocab=True, init_token=None, eos_token=None, fix_length=None, dtype=torch.int64, preprocessing=None, postprocessing=None, lower=False, tokenize=None, tokenizer_language='en', include_lengths=False, batch_first=False, pad_token='<pad>', unk_token='<unk>', pad_first=False, truncate_first=False, stop_words=None, is_target=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  build_vocab(self, *args, **kwargs)\n",
      " |      Construct the Vocab object for this field from one or more datasets.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          Positional arguments: Dataset objects or other iterable data\n",
      " |              sources from which to construct the Vocab object that\n",
      " |              represents the set of possible values for this field. If\n",
      " |              a Dataset object is provided, all columns corresponding\n",
      " |              to this field are used; individual columns can also be\n",
      " |              provided directly.\n",
      " |          Remaining keyword arguments: Passed to the constructor of Vocab.\n",
      " |  \n",
      " |  numericalize(self, arr, device=None)\n",
      " |      Turn a batch of examples that use this field into a Variable.\n",
      " |      \n",
      " |      If the field has include_lengths=True, a tensor of lengths will be\n",
      " |      included in the return value.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          arr (List[List[str]], or tuple of (List[List[str]], List[int])):\n",
      " |              List of tokenized and padded examples, or tuple of List of\n",
      " |              tokenized and padded examples and List of lengths of each\n",
      " |              example if self.include_lengths is True.\n",
      " |          device (str or torch.device): A string or instance of `torch.device`\n",
      " |              specifying which device the Variables are going to be created on.\n",
      " |              If left as default, the tensors will be created on cpu. Default: None.\n",
      " |  \n",
      " |  pad(self, minibatch)\n",
      " |      Pad a batch of examples using this field.\n",
      " |      \n",
      " |      Pads to self.fix_length if provided, otherwise pads to the length of\n",
      " |      the longest example in the batch. Prepends self.init_token and appends\n",
      " |      self.eos_token if those attributes are not None. Returns a tuple of the\n",
      " |      padded list and a list containing lengths of each example if\n",
      " |      `self.include_lengths` is `True` and `self.sequential` is `True`, else just\n",
      " |      returns the padded list. If `self.sequential` is `False`, no padding is applied.\n",
      " |  \n",
      " |  preprocess(self, x)\n",
      " |      Load a single example using this field, tokenizing if necessary.\n",
      " |      \n",
      " |      If the input is a Python 2 `str`, it will be converted to Unicode\n",
      " |      first. If `sequential=True`, it will be tokenized. Then the input\n",
      " |      will be optionally lowercased and passed to the user-provided\n",
      " |      `preprocessing` Pipeline.\n",
      " |  \n",
      " |  process(self, batch, device=None)\n",
      " |      Process a list of examples to create a torch.Tensor.\n",
      " |      \n",
      " |      Pad, numericalize, and postprocess a batch and create a tensor.\n",
      " |      \n",
      " |      Args:\n",
      " |          batch (list(object)): A list of object from a batch of examples.\n",
      " |      Returns:\n",
      " |          torch.autograd.Variable: Processed object given the input\n",
      " |          and custom postprocessing Pipeline.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  dtypes = {torch.float32: <class 'float'>, torch.float64: <class 'float...\n",
      " |  \n",
      " |  ignore = ['dtype', 'tokenize']\n",
      " |  \n",
      " |  vocab_cls = <class 'torchtext.vocab.Vocab'>\n",
      " |      Defines a vocabulary object that will be used to numericalize a field.\n",
      " |      \n",
      " |      Attributes:\n",
      " |          freqs: A collections.Counter object holding the frequencies of tokens\n",
      " |              in the data used to build the Vocab.\n",
      " |          stoi: A collections.defaultdict instance mapping token strings to\n",
      " |              numerical identifiers.\n",
      " |          itos: A list of token strings indexed by their numerical identifiers.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from RawField:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Field)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим словарь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in source (ru) vocabulary: 24764\n",
      "Unique tokens in target (en) vocabulary: 13\n",
      "['<unk>', '2', 'known', 'actually', 'series', 'reasons', 'financial', 'removed', 'newspaper', 'soft', 'imagine', 'theme', 'fill', 'contribute', 'pleased', 'thanks', \"world's\", 'adjustment', 'prayer', 'criminal', 'rank', 'variables', 'bold', 'angels', 'theirs', 'relating', 'molding', 'explosive', 'whip', 'lemon', 'byron', 'pearson', 'breaks', 'minnesota', 'whisper', 'framed', 'screens', 'bumblebees', 'hunt', 'reviews', 'atlas', 'forecast', 'pathological', 'tyranny', 'carmer', 'folly', 'negotiate', 'similarity', 'aborigine', 'clad', 'fe', 'lays', 'polar', 'spiritually', \"'round\", 'bong', 'decorator', 'formations', 'jelke', 'overcoming', 'rip', 'tedious', '10-year-old', 'banana', 'clinging', 'disrupted', 'florence', 'idly', 'lullaby', 'outputs', 'reconsider', 'skiffs', 'torque', 'wrapping', 'afghan', 'beatie', 'censure', 'corrugated', 'disinterest', 'falsity', 'grandiose', 'incandescent', 'lanes', 'millennia', 'organically', 'portray', 'repertory', 'shadowing', 'steadier', 'tranquilizers', 'wail', '1577', 'abolished', \"angel's\", 'balkans', 'bolsheviks', 'canvassers', 'clemency', 'contingent', 'davy', 'dispatches', 'emeritus', 'faiths', 'foreign-policy', 'going-over', 'heel-lotus', 'immemorial', 'irreproducibility', 'lapped', 'lunchtime', 'midair', 'negatively', 'orgies', 'pennock', 'pragmatism', 'radiator', 'reversal', 'scraps', 'skippers', 'steadied', 'tablespoonful', 'toughs', 'unprotected', 'well-kept']\n",
      "['<pad>', 'NOUN', 'VERB', '.', 'ADP', 'DET', 'ADJ', 'ADV', 'PRON', 'CONJ', 'PRT', 'NUM', 'X']\n"
     ]
    }
   ],
   "source": [
    "#[item for ex in train_data.examples for item in ex.words]\n",
    "\n",
    "WORD.build_vocab([ex.words for ex in train_data.examples], min_freq=2)\n",
    "TAG.build_vocab([ex.tags for ex in train_data.examples])\n",
    "\n",
    "print(f\"Unique tokens in source (ru) vocabulary: {len(WORD.vocab)}\")\n",
    "print(f\"Unique tokens in target (en) vocabulary: {len(TAG.vocab)}\")\n",
    "\n",
    "print(WORD.vocab.itos[::200])\n",
    "print(TAG.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'words': ['he', 'was', 'bitter', 'and', 'resentful', 'toward', 'her', ',', 'personally', 'resentful', '.'], 'tags': ['PRON', 'VERB', 'ADJ', 'CONJ', 'ADJ', 'ADP', 'PRON', '.', 'ADV', 'ADJ', '.']}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[9]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим с насколько большими предложениями мы имеем дело"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "length = map(len, [vars(x)['words'] for x in train_data.examples])\n",
    "\n",
    "plt.figure(figsize=[8, 4])\n",
    "plt.title(\"Length distribution in Train data\")\n",
    "plt.hist(list(length), bins=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для обучения BiLSTM лучше использовать colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для более быстрого и устойчивого обучения сгруппируем наши данные по батчам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# бьем нашу выборку на батч, не забывая сначала отсортировать выборку по длине\n",
    "def _len_sort_key(x):\n",
    "    return len(x.words)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE, \n",
    "    device = device,\n",
    "    sort_key=_len_sort_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1434, 180, 180]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# посморим  на количество батчей\n",
    "list(map(len, [train_iterator, valid_iterator, test_iterator]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель и её обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализируем нашу модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMTagger(\n",
       "  (embeddings): Embedding(24764, 100)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (rnn): LSTM(100, 64)\n",
       "  (tag): Linear(in_features=64, out_features=13, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, output_dim, dropout, bidirectional=False):\n",
    "        super().__init__()        \n",
    "  \n",
    "        self.embeddings = nn.Embedding(input_dim, emb_dim)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, bidirectional=bidirectional)\n",
    "        self.tag = nn.Linear((1 + bidirectional) * hid_dim, output_dim)\n",
    "\n",
    "    def forward(self, sent):\n",
    "        \n",
    "        #sent = [sent len, batch size] \n",
    "        \n",
    "        # не забываем применить dropout к embedding\n",
    "        embedded = self.dropout(self.embeddings(sent))\n",
    "\n",
    "        output, _ = self.rnn(embedded)\n",
    "        #output = [sent len, batch size, hid dim * n directions]\n",
    "\n",
    "        prediction = self.tag(output)\n",
    "    \n",
    "        return prediction\n",
    "        \n",
    "# параметры модели\n",
    "INPUT_DIM = len(WORD.vocab)\n",
    "OUTPUT_DIM = len(TAG.vocab)\n",
    "EMB_DIM = 100\n",
    "HID_DIM = 64\n",
    "DROPOUT = 0.5\n",
    "BIDIRECTIONAL = False\n",
    "\n",
    "model = LSTMTagger(INPUT_DIM, EMB_DIM, HID_DIM, OUTPUT_DIM, DROPOUT, BIDIRECTIONAL).to(device)\n",
    "\n",
    "# инициализируем веса\n",
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param, -0.08, 0.08)\n",
    "        \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подсчитаем количество обучаемых параметров нашей модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 2,519,741 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наша модель готова, осталось сформировать loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.5716, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for x in train_iterator:\n",
    "    break\n",
    "    \n",
    "output = model(x.words)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion(output.view(-1, output.shape[-1]), x.tags.view(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = TAG.vocab.stoi['<pad>']\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, clip, train_history=None, valid_history=None):\n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    history = []\n",
    "    for i, batch in enumerate(iterator):\n",
    "        \n",
    "        optimizer.zero_grad()        \n",
    "        output = model(batch.words)\n",
    "        \n",
    "        output = output.view(-1, output.shape[-1])\n",
    "        tags = batch.tags.view(-1)\n",
    "        \n",
    "        loss = criterion(output, tags)        \n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping(решение проблемы взрыва градиента), clip - максимальная норма вектора\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        history.append(loss.cpu().data.numpy())\n",
    "    \n",
    "    clear_output(True)            \n",
    "    if train_history is not None:\n",
    "        plt.plot(train_history, label='general train history')\n",
    "    if valid_history is not None:\n",
    "        plt.plot(valid_history, label='general valid history')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "        \n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    history = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "            output = model(batch.words)\n",
    "            \n",
    "            output = output.view(-1, output.shape[-1])\n",
    "            tags = batch.tags.view(-1)\n",
    "\n",
    "            loss = criterion(output, tags)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20\n",
      "\tTrain Loss: 0.059 | Train PPL:   1.061\n",
      "\t Val. Loss: 0.125 |  Val. PPL:   1.133\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'figure.figsize': (16, 12), 'font.size': 14})\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output\n",
    "\n",
    "train_history = []\n",
    "valid_history = []\n",
    "\n",
    "N_EPOCHS = 20\n",
    "CLIP = 100\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP, train_history, valid_history)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'best-val-model.pt')\n",
    "\n",
    "    train_history.append(train_loss)\n",
    "    valid_history.append(valid_loss)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02}')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим нашу модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_model(model, iterator):\n",
    "    model.eval()\n",
    "    \n",
    "    true_pred = 0\n",
    "    num_pred = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "            output = model(batch.words)\n",
    "            \n",
    "            #output = [sent len, batch size, output dim]\n",
    "            output = output.view(-1, output.shape[-1])\n",
    "            tags = batch.tags.view(-1)\n",
    "            \n",
    "            #output = [sent len, batch size]\n",
    "            predict_tags = np.argmax(output.cpu().numpy(), axis=1)\n",
    "            true_tags = tags.cpu().numpy()\n",
    "\n",
    "            #print(predict_tags)\n",
    "            #print(true_tags)\n",
    "            \n",
    "            true_pred += np.sum((true_tags == predict_tags) & (true_tags != PAD_IDX))\n",
    "            num_pred += np.prod(tags.shape)\n",
    "        \n",
    "    return round(true_pred / num_pred * 100, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 94.481 %\n"
     ]
    }
   ],
   "source": [
    "#humor dataset\n",
    "\n",
    "#HID_SIZE 16, 20 epochs => 53.514\n",
    "#HID_SIZE 32, 20 epochs => 60.638\n",
    "#HID_SIZE 32, EMB_DIM = 64, 20 epochs => 61.734\n",
    "#HID_SIZE 64, EMB_DIM = 100, 20 epochs => 62.347\n",
    "\n",
    "#full dataset\n",
    "\n",
    "#HID_SIZE 64, EMB_DIM = 100, 20 epochs =>\n",
    "\n",
    "print(\"Accuracy:\", accuracy_model(model, test_iterator), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы обучили нашу модель сначала на части датасета (категория humor), потом на полном датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = LSTMTagger(INPUT_DIM, EMB_DIM, HID_DIM, OUTPUT_DIM, DROPOUT, BIDIRECTIONAL).to(device)\n",
    "best_model.load_state_dict(torch.load('best-val-model.pt'))\n",
    "\n",
    "assert accuracy_model(best_model, test_iterator) >= 92"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример решения нашей задачи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tags(model, data):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        words, _ = data\n",
    "        example = torch.LongTensor([WORD.vocab.stoi[elem] for elem in words]).unsqueeze(1).to(device)\n",
    "        \n",
    "        output = model(example).argmax(dim=-1).cpu().numpy()\n",
    "        tags = [TAG.vocab.itos[int(elem)] for elem in output]\n",
    "\n",
    "        for token, tag in zip(words, tags):\n",
    "            print(f'{token:15s}{tag}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From           NOUN\n",
      "what           DET\n",
      "I              VERB\n",
      "was            VERB\n",
      "able           ADJ\n",
      "to             PRT\n",
      "gauge          NOUN\n",
      "in             ADP\n",
      "a              DET\n",
      "swift          ADJ\n",
      ",              .\n",
      "greedy         ADJ\n",
      "glance         NOUN\n",
      ",              .\n",
      "the            DET\n",
      "figure         NOUN\n",
      "inside         ADP\n",
      "the            DET\n",
      "coral-colored  ADJ\n",
      "boucle         NOUN\n",
      "dress          NOUN\n",
      "was            VERB\n",
      "stupefying     VERB\n",
      ".              .\n"
     ]
    }
   ],
   "source": [
    "print_tags(model, pos_data[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сравните результаты моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы применили ряд моделей для задачи POS tagging.\n",
    "\n",
    "Результаты:\n",
    "\n",
    "1. Модель с использованием вероятностей (Марковские цепи). Точность 89.4%\n",
    "2. Наивная модель (DefaultTagger). Точность 20%\n",
    "3. Модель от Стенфорда. Точность 90.9%\n",
    "4. Нейросетевая модель (BiLSTM). Точность 94.5%\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
