{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "import pprint\n",
    "from nltk.corpus import brown\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import OrderedDict, deque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POS tagging\n",
    "\n",
    "\n",
    "<img src=\"https://blog.aaronccwong.com/assets/images/bigram-hmm/pos-title.jpg\" alt=\"topic_modeling\" style=\"width: 620px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the texts to tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Sergei\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use', 'not', 'would', 'say', 'could', '_', 'be', 'know', 'good', 'go', 'get', 'do', 'done', 'try', 'many', 'some', 'nice', 'thank', 'think', 'see', 'rather', 'easy', 'easily', 'lot', 'lack', 'make', 'want', 'seem', 'run', 'need', 'even', 'right', 'line', 'even', 'also', 'may', 'take', 'come'])\n",
    "\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('wiki_lingvo.txt', mode='r', encoding='utf-8') as file:\n",
    "    text = file.readlines()\n",
    "    \n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<p><b>Leipon</b>, or <b>Pityilu</b>, is an Austronesian language spoken on Hauwai, Ndrilo, and Pityilu islands, just off Manus Island in Papua New Guinea. </p>\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete html tags\n",
    "text = [BeautifulSoup(t, 'lxml').text for t in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Judeo-Yemeni Arabic (also known as Judeo-Yemeni and Yemenite Judeo-Arabic) is a variety of Arabic spoken by Jews living or formerly living in Yemen. The language is quite different from mainstream Yemeni Arabic, and is written in the Hebrew alphabet. The cities of Sana'a, Aden, al-Bayda, and Habban District and the villages in their districts each have (or had) their own dialect.The vast majority of Yemenite Jews have relocated to Israel and have shifted to Modern Hebrew as their first language. In 1995, Israel was home to 50,000 speakers of Judeo-Yemeni in 1995, while 1,000 remained in Yemen.  According to Yemeni rabbi al-Marhabi, most of these have since left for the United States. As of  2010, fewer than 300 Jews were believed to remain in Yemen.\\n\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tagging model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\Sergei\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\Sergei\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"brown\")\n",
    "nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DET'),\n",
       " ('Fulton', 'NOUN'),\n",
       " ('County', 'NOUN'),\n",
       " ('Grand', 'ADJ'),\n",
       " ('Jury', 'NOUN'),\n",
       " ('said', 'VERB'),\n",
       " ('Friday', 'NOUN'),\n",
       " ('an', 'DET'),\n",
       " ('investigation', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " (\"Atlanta's\", 'NOUN'),\n",
       " ('recent', 'ADJ'),\n",
       " ('primary', 'NOUN'),\n",
       " ('election', 'NOUN'),\n",
       " ('produced', 'VERB'),\n",
       " ('``', '.'),\n",
       " ('no', 'DET'),\n",
       " ('evidence', 'NOUN'),\n",
       " (\"''\", '.'),\n",
       " ('that', 'ADP'),\n",
       " ('any', 'DET'),\n",
       " ('irregularities', 'NOUN'),\n",
       " ('took', 'VERB'),\n",
       " ('place', 'NOUN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown_tagged_sents = brown.tagged_sents(tagset=\"universal\")\n",
    "brown_tagged_sents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_tagged_words = brown.tagged_words(tagset='universal')\n",
    "brown_tagged_words = list(map(lambda x: (x[0].lower(), x[1]), brown_tagged_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('the', 'DET')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown_tagged_words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = [tag for (word, tag) in brown_tagged_words]\n",
    "words = [word for (word, tag) in brown_tagged_words]\n",
    "\n",
    "tag_num = pd.Series(nltk.FreqDist(tags)).sort_values(ascending=False)\n",
    "word_num = pd.Series(nltk.FreqDist(words)).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_tagged_sents = brown.tagged_sents(tagset=\"universal\")\n",
    "my_brown_tagged_sents = []\n",
    "\n",
    "for sent in brown_tagged_sents:\n",
    "    my_brown_tagged_sents.append(list(map(lambda x: (x[0].lower(),x[1]), sent)))\n",
    "\n",
    "my_brown_tagged_sents = np.array(my_brown_tagged_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sents, test_sents = train_test_split(my_brown_tagged_sents, test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets train simple HMM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiddenMarkovModel:    \n",
    "    def __init__(self):\n",
    "    \n",
    "        pass\n",
    "        \n",
    "    def fit(self, train_tokens_tags_list):\n",
    "        tags = [tag for sent in train_tokens_tags_list\n",
    "                    for (word, tag) in sent]\n",
    "        words = [word for sent in train_tokens_tags_list\n",
    "                      for (word, tag) in sent]\n",
    "        \n",
    "        tag_num = pd.Series(nltk.FreqDist(tags)).sort_index()\n",
    "        word_num = pd.Series(nltk.FreqDist(words)).sort_values(ascending=False)\n",
    "         \n",
    "        self.tags = tag_num.index\n",
    "        self.words = word_num.index\n",
    "        \n",
    "        A = pd.DataFrame({'{}'.format(tag) : [0] * len(tag_num) for tag in tag_num.index}, index=tag_num.index)\n",
    "        B = pd.DataFrame({'{}'.format(tag) : [0] * len(word_num) for tag in tag_num.index}, index=word_num.index)\n",
    "        \n",
    "        for sent in train_tokens_tags_list:\n",
    "            for i in range(len(sent)):\n",
    "                B.loc[sent[i][0], sent[i][1]] += 1\n",
    "                if len(sent) - 1 != i:\n",
    "                    A.loc[sent[i][1], sent[i + 1][1]] += 1\n",
    "                    \n",
    "        A = A.divide(A.sum(axis=1), axis=0)        \n",
    "        B = B / np.sum(B, axis=0)        \n",
    "        self.A = A\n",
    "        self.B = B\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    \n",
    "    def predict(self, test_tokens_list):\n",
    "        predict_tags = OrderedDict({i : np.array([]) for i in range(len(test_tokens_list))})\n",
    "        \n",
    "        for i_sent in range(len(test_tokens_list)):\n",
    "            \n",
    "            current_sent = test_tokens_list[i_sent]\n",
    "            len_sent = len(current_sent)\n",
    "            \n",
    "            q = np.zeros(shape=(len_sent + 1, len(self.tags)))\n",
    "            q[0] = 1\n",
    "            back_point = np.zeros(shape=(len_sent + 1, len(self.tags)))\n",
    "            \n",
    "            for t in range(len_sent):\n",
    "                \n",
    "                if current_sent[t] not in self.words:\n",
    "                    current_sent[t] = 'time' #most popular word in corpus\n",
    "                    \n",
    "                for i_s in range(len(self.tags)):                    \n",
    "                    s = self.tags[i_s]\n",
    "                    \n",
    "                    q[t + 1][i_s] = np.max(q[t,:] *\n",
    "                        self.A.loc[:, s] * \n",
    "                        self.B.loc[current_sent[t], s])\n",
    "                    \n",
    "                    back_point[t + 1][i_s] = (q[t,:] *\n",
    "                        self.A.loc[:, s] * \n",
    "                        self.B.loc[current_sent[t], s]).reset_index()[s].idxmax()\n",
    "                    \n",
    "            back_point = back_point.astype('int')\n",
    "            \n",
    "            back_tag = deque()\n",
    "            current_tag = np.argmax(q[len_sent])\n",
    "            for t in range(len_sent, 0, -1):\n",
    "                back_tag.appendleft(self.tags[current_tag])\n",
    "                current_tag = back_point[t, current_tag]\n",
    "             \n",
    "            predict_tags[i_sent] = np.array(back_tag)\n",
    "        \n",
    "        \n",
    "        return predict_tags   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.HiddenMarkovModel at 0x1dc39367408>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markov_model = HiddenMarkovModel()\n",
    "markov_model.fit(train_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Leipon',\n",
       " ',',\n",
       " 'or',\n",
       " 'Pityilu',\n",
       " ',',\n",
       " 'is',\n",
       " 'an',\n",
       " 'Austronesian',\n",
       " 'language',\n",
       " 'spoken',\n",
       " 'on',\n",
       " 'Hauwai',\n",
       " ',',\n",
       " 'Ndrilo',\n",
       " ',',\n",
       " 'and',\n",
       " 'Pityilu',\n",
       " 'islands',\n",
       " ',',\n",
       " 'just',\n",
       " 'off',\n",
       " 'Manus',\n",
       " 'Island',\n",
       " 'in',\n",
       " 'Papua',\n",
       " 'New',\n",
       " 'Guinea',\n",
       " '.']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "word_tokenize(text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import OrderedDict\n",
    "pop_word = 'time'\n",
    "pred = markov_model.predict([word_tokenize(text[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Leipon', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('or', 'CONJ'),\n",
       " ('Pityilu', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('is', 'VERB'),\n",
       " ('an', 'DET'),\n",
       " ('Austronesian', 'NOUN'),\n",
       " ('language', 'NOUN'),\n",
       " ('spoken', 'VERB'),\n",
       " ('on', 'ADP'),\n",
       " ('Hauwai', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('Ndrilo', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('and', 'CONJ'),\n",
       " ('Pityilu', 'NOUN'),\n",
       " ('islands', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('just', 'ADV'),\n",
       " ('off', 'ADP'),\n",
       " ('Manus', 'NOUN'),\n",
       " ('Island', 'NOUN'),\n",
       " ('in', 'ADP'),\n",
       " ('Papua', 'NOUN'),\n",
       " ('New', 'NOUN'),\n",
       " ('Guinea', 'NOUN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(word_tokenize(text[0]), pred[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Xiqi', 'NOUN'),\n",
       " ('(', '.'),\n",
       " ('Chinese', 'NOUN'),\n",
       " (':', '.'),\n",
       " ('西期', 'NOUN'),\n",
       " (';', '.'),\n",
       " ('autonym', 'NOUN'),\n",
       " (':', '.'),\n",
       " ('ɕi33', 'NOUN'),\n",
       " ('tɕhi33', 'NOUN'),\n",
       " ('pho21', 'NOUN'),\n",
       " (')', '.'),\n",
       " ('is', 'VERB'),\n",
       " ('an', 'DET'),\n",
       " ('unclassified', 'NOUN'),\n",
       " ('Loloish', 'NOUN'),\n",
       " ('language', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('Huaning', 'NOUN'),\n",
       " ('County', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('Yunnan', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('China', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('It', 'NOUN'),\n",
       " ('is', 'VERB'),\n",
       " ('also', 'ADV'),\n",
       " ('called', 'VERB'),\n",
       " ('Siqipo', 'NOUN'),\n",
       " ('斯期颇', 'NOUN'),\n",
       " ('(', '.'),\n",
       " ('sɿ55', 'NOUN'),\n",
       " ('tɕhi55', 'NOUN'),\n",
       " ('pho21', 'NOUN'),\n",
       " (')', '.'),\n",
       " ('in', 'ADP'),\n",
       " ('Mile', 'NOUN'),\n",
       " ('County.Pelkey', 'NOUN'),\n",
       " ('(', '.'),\n",
       " ('2011:431', 'NOUN'),\n",
       " (')', '.'),\n",
       " ('suggests', 'VERB'),\n",
       " ('that', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('Xiqi', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('Ati', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('and', 'CONJ'),\n",
       " ('Long', 'NOUN'),\n",
       " ('languages', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('Huaning', 'NOUN'),\n",
       " ('County', 'NOUN'),\n",
       " ('may', 'VERB'),\n",
       " ('be', 'VERB'),\n",
       " ('Southeastern', 'NOUN'),\n",
       " ('Loloish', 'NOUN'),\n",
       " ('languages', 'NOUN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(word_tokenize(text[12]), markov_model.predict([word_tokenize(text[12])])[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stanford model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag.stanford import StanfordPOSTagger\n",
    "from nltk.tag.mapping import map_tag\n",
    "\n",
    "jar = u'D:\\ml\\stanford-postagger-2018-10-16\\stanford-postagger-3.9.2.jar'\n",
    "model = u'D:\\ml\\stanford-postagger-2018-10-16\\models\\english-bidirectional-distsim.tagger'\n",
    "stanford_tagger = StanfordPOSTagger(model, jar, encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Leipon', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('or', 'CONJ'),\n",
       " ('Pityilu', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('is', 'VERB'),\n",
       " ('an', 'DET'),\n",
       " ('Austronesian', 'ADJ'),\n",
       " ('language', 'NOUN'),\n",
       " ('spoken', 'VERB'),\n",
       " ('on', 'ADP'),\n",
       " ('Hauwai', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('Ndrilo', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('and', 'CONJ'),\n",
       " ('Pityilu', 'NOUN'),\n",
       " ('islands', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('just', 'ADV'),\n",
       " ('off', 'ADP'),\n",
       " ('Manus', 'NOUN'),\n",
       " ('Island', 'NOUN'),\n",
       " ('in', 'ADP'),\n",
       " ('Papua', 'NOUN'),\n",
       " ('New', 'NOUN'),\n",
       " ('Guinea', 'NOUN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_sent = stanford_tagger.tag(word_tokenize(text[0]))\n",
    "list(zip(word_tokenize(text[0]), [map_tag('en-ptb', 'universal', tag) for token, tag in tagged_sent]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stanford German model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "german_text = 'Paul Cézanne war ein französischer Maler. Cézannes Werk wird unterschiedlichen Stilrichtungen zugeordnet: Während seine frühen Arbeiten noch von Romantik – wie die Wandbilder im Landhaus Jas de Bouffan – und Realismus geprägt sind, gelangte er durch intensive Auseinandersetzung mit impressionistischen Ausdrucksformen zu einer neuen Bildsprache, die den zerfließenden Bildeindruck impressionistischer Werke zu festigen versucht. Er gab die illusionistische Fernwirkung auf, brach die von den Vertretern der Akademischen Kunst aufgestellten Regeln und strebte eine Erneuerung klassischer Gestaltungsmethoden auf der Grundlage des impressionistischen Farbraumes und farbmodulatorischer Prinzipien an.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "jar = u'D:\\ml\\stanford-postagger-full-2017-06-09\\stanford-postagger-3.8.0.jar'\n",
    "model = u'D:\\ml\\stanford-postagger-full-2017-06-09\\models\\german-ud.tagger'\n",
    "stanford_tagger = StanfordPOSTagger(model, jar, encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Paul', 'PROPN'),\n",
       " ('Cézanne', 'PROPN'),\n",
       " ('war', 'VERB'),\n",
       " ('ein', 'DET'),\n",
       " ('französischer', 'ADJ'),\n",
       " ('Maler', 'NOUN'),\n",
       " ('.', 'PUNCT'),\n",
       " ('Cézannes', 'PROPN'),\n",
       " ('Werk', 'PROPN'),\n",
       " ('wird', 'AUX'),\n",
       " ('unterschiedlichen', 'ADJ'),\n",
       " ('Stilrichtungen', 'NOUN'),\n",
       " ('zugeordnet', 'VERB'),\n",
       " (':', 'PUNCT'),\n",
       " ('Während', 'SCONJ'),\n",
       " ('seine', 'DET'),\n",
       " ('frühen', 'ADJ'),\n",
       " ('Arbeiten', 'NOUN'),\n",
       " ('noch', 'ADV'),\n",
       " ('von', 'ADP'),\n",
       " ('Romantik', 'NOUN'),\n",
       " ('–', 'X'),\n",
       " ('wie', 'ADP'),\n",
       " ('die', 'DET'),\n",
       " ('Wandbilder', 'NOUN'),\n",
       " ('im', 'ADP'),\n",
       " ('Landhaus', 'NOUN'),\n",
       " ('Jas', 'PROPN'),\n",
       " ('de', 'PROPN'),\n",
       " ('Bouffan', 'PROPN'),\n",
       " ('–', 'PROPN'),\n",
       " ('und', 'CONJ'),\n",
       " ('Realismus', 'NOUN'),\n",
       " ('geprägt', 'VERB'),\n",
       " ('sind', 'AUX'),\n",
       " (',', 'PUNCT'),\n",
       " ('gelangte', 'VERB'),\n",
       " ('er', 'PRON'),\n",
       " ('durch', 'ADP'),\n",
       " ('intensive', 'ADJ'),\n",
       " ('Auseinandersetzung', 'NOUN'),\n",
       " ('mit', 'ADP'),\n",
       " ('impressionistischen', 'ADJ'),\n",
       " ('Ausdrucksformen', 'NOUN'),\n",
       " ('zu', 'ADP'),\n",
       " ('einer', 'DET'),\n",
       " ('neuen', 'ADJ'),\n",
       " ('Bildsprache', 'NOUN'),\n",
       " (',', 'PUNCT'),\n",
       " ('die', 'PRON'),\n",
       " ('den', 'DET'),\n",
       " ('zerfließenden', 'ADJ'),\n",
       " ('Bildeindruck', 'NOUN'),\n",
       " ('impressionistischer', 'ADJ'),\n",
       " ('Werke', 'NOUN'),\n",
       " ('zu', 'PART'),\n",
       " ('festigen', 'VERB'),\n",
       " ('versucht', 'VERB'),\n",
       " ('.', 'PUNCT'),\n",
       " ('Er', 'PRON'),\n",
       " ('gab', 'VERB'),\n",
       " ('die', 'DET'),\n",
       " ('illusionistische', 'ADJ'),\n",
       " ('Fernwirkung', 'NOUN'),\n",
       " ('auf', 'ADP'),\n",
       " (',', 'PUNCT'),\n",
       " ('brach', 'VERB'),\n",
       " ('die', 'DET'),\n",
       " ('von', 'ADP'),\n",
       " ('den', 'DET'),\n",
       " ('Vertretern', 'NOUN'),\n",
       " ('der', 'DET'),\n",
       " ('Akademischen', 'PROPN'),\n",
       " ('Kunst', 'PROPN'),\n",
       " ('aufgestellten', 'ADJ'),\n",
       " ('Regeln', 'NOUN'),\n",
       " ('und', 'CONJ'),\n",
       " ('strebte', 'VERB'),\n",
       " ('eine', 'DET'),\n",
       " ('Erneuerung', 'NOUN'),\n",
       " ('klassischer', 'ADJ'),\n",
       " ('Gestaltungsmethoden', 'NOUN'),\n",
       " ('auf', 'ADP'),\n",
       " ('der', 'DET'),\n",
       " ('Grundlage', 'NOUN'),\n",
       " ('des', 'DET'),\n",
       " ('impressionistischen', 'ADJ'),\n",
       " ('Farbraumes', 'NOUN'),\n",
       " ('und', 'CONJ'),\n",
       " ('farbmodulatorischer', 'ADJ'),\n",
       " ('Prinzipien', 'NOUN'),\n",
       " ('an', 'ADP'),\n",
       " ('.', 'PUNCT')]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_sent = stanford_tagger.tag(word_tokenize(german_text))\n",
    "list(zip(word_tokenize(german_text), [tag for token, tag in tagged_sent]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
